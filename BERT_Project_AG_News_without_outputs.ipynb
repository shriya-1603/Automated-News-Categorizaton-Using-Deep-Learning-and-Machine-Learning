{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k7rS0lDtf40"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import make_scorer, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv2Ln2uvtf41"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/train.csv\"\n",
        "\n",
        "total_rows = 120000\n",
        "\n",
        "number_of_rows = 10000\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "np.random.seed(random_state)\n",
        "skip = sorted(np.random.choice(np.arange(1, total_rows+1), (total_rows - number_of_rows), replace=False))\n",
        "\n",
        "dataset = pd.read_csv(file_path, skiprows=skip)\n",
        "print(dataset.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klGm5jzHtf41"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U49S8hs0tf41"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MDjeq0Vtf41"
      },
      "outputs": [],
      "source": [
        "print(dataset.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmiVuX_4tf41"
      },
      "outputs": [],
      "source": [
        "dataset['Title'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQa1aw-Etf42"
      },
      "outputs": [],
      "source": [
        "target_category = dataset['Class Index'].unique()\n",
        "print(target_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nErRyVrVtf42"
      },
      "outputs": [],
      "source": [
        "dataset['CategoryId'] = dataset['Class Index'].factorize()[0]\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWcL9kTstf42"
      },
      "outputs": [],
      "source": [
        "category = dataset[['Class Index', 'CategoryId']].drop_duplicates().sort_values('CategoryId')\n",
        "category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w8jtTjMtf42"
      },
      "outputs": [],
      "source": [
        "category_counts = dataset['Class Index'].value_counts()\n",
        "category_counts.plot(kind=\"bar\", color=[\"pink\", \"orange\", \"red\", \"yellow\"])\n",
        "plt.xlabel(\"Category of data\")\n",
        "plt.ylabel(\"Number of articles\")\n",
        "plt.title(\"Visualize numbers of Category of data\")\n",
        "plt.xticks(ticks=range(len(category_counts)), labels=['World News', 'Sports News', 'Business News', 'Science & Tech'], rotation=0)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxz0AZlRtf42"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counts = dataset['CategoryId'].value_counts().sort_index()\n",
        "\n",
        "categories = ['World News', 'Sports News', 'Business News', 'Science & Tech']\n",
        "\n",
        "colors = ['skyblue', 'green', 'red', 'purple']\n",
        "\n",
        "explode = [0.1] * len(categories)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(counts, labels=categories, autopct='%1.1f%%', colors=colors, startangle=140, explode=explode)\n",
        "plt.title('Distribution of News Categories')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKKWnFwqtf42"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "STOP_WORDS = stopwords.words('english')\n",
        "stopwords = set(STOP_WORDS)\n",
        "stopwords.add(\"said\")\n",
        "stopwords.remove(\"not\")\n",
        "stopwords.remove(\"no\")\n",
        "stopwords.add(\" \")\n",
        "\n",
        "def generate_wordcloud(text, title):\n",
        "    plt.figure(figsize=(10, 15))\n",
        "    wc = WordCloud(max_words=500, background_color='white', stopwords=stopwords)\n",
        "    wc.generate(\" \".join(text))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "for index, category in enumerate(['World', 'Sports', 'Business', 'Sci-Tech'], start=1):\n",
        "    category_text = dataset['Description'][dataset['Class Index'] == index]\n",
        "    generate_wordcloud(category_text, category)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dlMqElhtf42"
      },
      "outputs": [],
      "source": [
        "def remove_tags(text):\n",
        "    remove = re.compile(r'<.*?>')\n",
        "    return re.sub(remove, '', text)\n",
        "\n",
        "dataset['Description'] = dataset['Description'].apply(remove_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UzNREl3tf42"
      },
      "outputs": [],
      "source": [
        "def special_char(text):\n",
        "  reviews = ''\n",
        "  for x in text:\n",
        "    if x.isalnum():\n",
        "      reviews = reviews + x\n",
        "    else:\n",
        "      reviews = reviews + ' '\n",
        "  return reviews\n",
        "dataset['Description'] = dataset['Description'].apply(special_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW43sp6ltf42"
      },
      "outputs": [],
      "source": [
        "def convert_lower(text):\n",
        "   return text.lower()\n",
        "dataset['Description'] = dataset['Description'].apply(convert_lower)\n",
        "dataset['Description'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh1Q88Eatf42"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    return [x for x in words if x.lower() not in stop_words]\n",
        "\n",
        "dataset['Description'] = dataset['Description'].apply(remove_stopwords)\n",
        "\n",
        "dataset['Description'][1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhMB-oQxtf42"
      },
      "outputs": [],
      "source": [
        "def lemmatize_word(text):\n",
        "  wordnet = WordNetLemmatizer()\n",
        "  return \" \".join([wordnet.lemmatize(word) for word in text])\n",
        "dataset['Description'] = dataset['Description'].apply(lemmatize_word)\n",
        "dataset['Description'][1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "6TqKagLXKvuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-cnleLktf42"
      },
      "outputs": [],
      "source": [
        "x = dataset['Description']\n",
        "y = dataset['CategoryId']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bag of words"
      ],
      "metadata": {
        "id": "SVXR_-6bV902"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYMU0eh5tf43"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "x = np.array(dataset.iloc[:,0].values)\n",
        "y = np.array(dataset.CategoryId.values)\n",
        "cv = CountVectorizer(max_features = 5000)\n",
        "x = cv.fit_transform(dataset.Description).toarray()\n",
        "print(\"X.shape = \",x.shape)\n",
        "print(\"y.shape = \",y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-1a0ZEytf43"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)\n",
        "print(len(x_train))\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyNwrAzAtf43"
      },
      "outputs": [],
      "source": [
        "perform_list = [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfi5Fadltf43"
      },
      "outputs": [],
      "source": [
        "def run_model(model_name, est_c, est_pnlty):\n",
        "\n",
        "    mdl = ''\n",
        "\n",
        "    if model_name == 'Logistic Regression':\n",
        "        mdl = LogisticRegression()\n",
        "\n",
        "    elif model_name == 'Random Forest':\n",
        "        mdl = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
        "\n",
        "    elif model_name == 'Multinomial Naive Bayes':\n",
        "        mdl = MultinomialNB(alpha=1.0, fit_prior=True)\n",
        "\n",
        "    elif model_name == 'Support Vector Classifier':\n",
        "        mdl = SVC()\n",
        "\n",
        "    elif model_name == 'Decision Tree Classifier':\n",
        "        mdl = DecisionTreeClassifier()\n",
        "\n",
        "    elif model_name == 'K Nearest Neighbour':\n",
        "        mdl = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=4)\n",
        "\n",
        "    elif model_name == 'Gaussian Naive Bayes':\n",
        "        mdl = GaussianNB()\n",
        "\n",
        "    oneVsRest = OneVsRestClassifier(mdl)\n",
        "    oneVsRest.fit(x_train, y_train)\n",
        "    y_pred = oneVsRest.predict(x_test)\n",
        "\n",
        "    accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
        "\n",
        "    precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
        "\n",
        "    print(f'Test Accuracy Score of Basic {model_name}: % {accuracy}')\n",
        "    print(f'Precision : {precision}')\n",
        "    print(f'Recall : {recall}')\n",
        "    print(f'F1-score : {f1score}')\n",
        "\n",
        "    perform_list.append(dict([\n",
        "        ('Model', model_name),\n",
        "        ('Test Accuracy', round(accuracy, 2)),\n",
        "        ('Precision', round(precision, 2)),\n",
        "        ('Recall', round(recall, 2)),\n",
        "        ('F1', round(f1score, 2))\n",
        "    ]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP05-NbItf43"
      },
      "outputs": [],
      "source": [
        "# run_model('Logistic Regression', est_c=None, est_pnlty=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDcGxOk4tf43"
      },
      "outputs": [],
      "source": [
        "run_model('Random Forest', est_c=None, est_pnlty=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la2mP8W5tf43"
      },
      "outputs": [],
      "source": [
        "run_model('Multinomial Naive Bayes', est_c=None, est_pnlty=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8voKEIBItf43"
      },
      "outputs": [],
      "source": [
        "run_model('Decision Tree Classifier', est_c=None, est_pnlty=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BsK5_NQtf43"
      },
      "outputs": [],
      "source": [
        "run_model('Gaussian Naive Bayes', est_c=None, est_pnlty=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lghf0c4Utf43"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "model_performance = pd.DataFrame(data=perform_list)\n",
        "model_performance = model_performance[['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1']]\n",
        "\n",
        "display(Markdown(\"# Bag of Words Model Performance metrics\"))\n",
        "\n",
        "display(model_performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE3OVk1Otf43"
      },
      "outputs": [],
      "source": [
        "model = model_performance[\"Model\"]\n",
        "max_value = model_performance[\"Test Accuracy\"].max()\n",
        "print(\"The best accuracy of model is\", max_value,\"from Random\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPgPwGgltf43"
      },
      "outputs": [],
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0).fit(x_train, y_train)\n",
        "classifier\n",
        "y_pred = classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gItlka6vtf44"
      },
      "outputs": [],
      "source": [
        "y_pred1 = cv.transform(['Hour ago, I contemplated retirement for a lot of reasons. I felt like people were not sensitive enough to my injuries. I felt like a lot of people were backed, why not me? I have done no less. I have won a lot of games for the team, and I am not feeling backed, said Ashwin'])\n",
        "yy = classifier.predict(y_pred1)\n",
        "result = \"\"\n",
        "\n",
        "if yy == [1]:\n",
        "  result = \"World News\"\n",
        "elif yy == [2]:\n",
        "  result = \"Sports News\"\n",
        "elif yy == [3]:\n",
        "  result = \"Business News\"\n",
        "elif yy == [4]:\n",
        "  result = \"Science & Tech News\"\n",
        "\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word2Vec"
      ],
      "metadata": {
        "id": "3E2tRKByeaS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "id": "sVt7nRLwQbY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "tokenized_texts = [word_tokenize(text.lower()) for text in dataset['Description']]\n",
        "\n",
        "model_w2v = Word2Vec(tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "word_vectors = model_w2v.wv\n",
        "\n",
        "\n",
        "def document_vector(word_vec_model, doc):\n",
        "    doc_vector = np.mean([word_vec_model[word] for word in doc if word in word_vec_model.key_to_index], axis=0)\n",
        "    return doc_vector\n",
        "\n",
        "\n",
        "document_vectors = np.array([document_vector(word_vectors, doc) for doc in tokenized_texts if any(word in word_vectors.key_to_index for word in doc)])\n",
        "\n",
        "\n",
        "valid_labels = dataset['CategoryId'][[any(word in word_vectors.key_to_index for word in doc) for doc in tokenized_texts]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(document_vectors, valid_labels, test_size=0.3, random_state=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qv1rxWVIeb_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "id": "VfDmHX_xfMAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_list2 = [ ]\n"
      ],
      "metadata": {
        "id": "3Q58menKfODO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(model_name, est_c, est_pnlty):\n",
        "\n",
        "    mdl = ''\n",
        "\n",
        "    if model_name == 'Logistic Regression':\n",
        "        mdl = LogisticRegression()\n",
        "\n",
        "    elif model_name == 'Random Forest':\n",
        "        mdl = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
        "\n",
        "    elif model_name == 'Multinomial Naive Bayes':\n",
        "        mdl = MultinomialNB(alpha=1.0, fit_prior=True)\n",
        "\n",
        "    elif model_name == 'Support Vector Classifier':\n",
        "        mdl = SVC()\n",
        "\n",
        "    elif model_name == 'Decision Tree Classifier':\n",
        "        mdl = DecisionTreeClassifier()\n",
        "\n",
        "    elif model_name == 'K Nearest Neighbour':\n",
        "        mdl = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=4)\n",
        "\n",
        "    elif model_name == 'Gaussian Naive Bayes':\n",
        "        mdl = GaussianNB()\n",
        "\n",
        "    oneVsRest = OneVsRestClassifier(mdl)\n",
        "    oneVsRest.fit(X_train, y_train)\n",
        "    y_pred = oneVsRest.predict(X_test)\n",
        "\n",
        "    accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
        "\n",
        "    precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
        "\n",
        "    print(f'Test Accuracy Score of Basic {model_name}: % {accuracy}')\n",
        "    print(f'Precision : {precision}')\n",
        "    print(f'Recall : {recall}')\n",
        "    print(f'F1-score : {f1score}')\n",
        "\n",
        "    perform_list2.append(dict([\n",
        "        ('Model', model_name),\n",
        "        ('Test Accuracy', round(accuracy, 2)),\n",
        "        ('Precision', round(precision, 2)),\n",
        "        ('Recall', round(recall, 2)),\n",
        "        ('F1', round(f1score, 2))\n",
        "    ]))\n"
      ],
      "metadata": {
        "id": "5jsIuzVafQSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Logistic Regression', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "YOCruIolfRoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Random Forest', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "DTBf6Zs2fVBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_model('Multinomial Naive Bayes', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "4yP9kmhpfXH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_model('Support Vector Classifer', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "4jjaSS3gfY9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Decision Tree Classifier', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "KL1X8Xz4fbJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('K Nearest Neighbour', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "e1PCQRY_fc8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Gaussian Naive Bayes', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "MXaAI4Uife0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance = pd.DataFrame(data=perform_list2)\n",
        "model_performance = model_performance[['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1']]\n",
        "\n",
        "display(Markdown(\"# Word2Vec Model Performance metrics\"))\n",
        "\n",
        "display(model_performance)"
      ],
      "metadata": {
        "id": "mZOmSq5bfg6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_performance[\"Model\"]\n",
        "max_value = model_performance[\"Test Accuracy\"].max()\n",
        "print(\"The best accuracy of model is\", max_value,\"from Random\")"
      ],
      "metadata": {
        "id": "VExI7Nf-fipR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0).fit(X_train, y_train)\n",
        "classifier\n",
        "y_pred = classifier.predict(X_test)\n"
      ],
      "metadata": {
        "id": "ihZ3SICofkmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dataset['Description']\n",
        "y = dataset['CategoryId']\n",
        "\n",
        "\n",
        "cv = CountVectorizer(max_features=100)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)\n",
        "\n",
        "classifier = RandomForestClassifier(random_state=0)\n",
        "\n",
        "classifier.fit(X_train_cv, y_train)\n",
        "\n",
        "new_text = ['Hour ago, I contemplated retirement for a lot of reasons. I felt like people were not sensitive enough to my injuries. I felt like a lot of people were backed, why not me? I have done no less. I have won a lot of games for the team, and I am not feeling backed, said Ashwin']\n",
        "new_text_cv = cv.transform(new_text)\n",
        "\n",
        "y_pred = classifier.predict(new_text_cv)\n",
        "\n"
      ],
      "metadata": {
        "id": "xitRURAzfmf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "category_id_to_name = {\n",
        "    1: \"World News\",\n",
        "    2: \"Sports News\",\n",
        "    3: \"Business News\",\n",
        "    4: \"Sci/Tech News\"\n",
        "}\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(new_text_cv)\n",
        "\n",
        "predicted_category_name = category_id_to_name.get(y_pred[0], 'Unknown Category')\n",
        "\n",
        "print(f\"The news is classified as: {predicted_category_name}\")\n"
      ],
      "metadata": {
        "id": "cvo2avdQgg8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF"
      ],
      "metadata": {
        "id": "4FzWwhRZWCNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x = np.array(dataset.iloc[:, 0].values)\n",
        "y = np.array(dataset['CategoryId'].values)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "x = tfidf.fit_transform(dataset['Description']).toarray()\n",
        "\n",
        "print(\"X.shape = \", x.shape)\n",
        "print(\"y.shape = \", y.shape)\n"
      ],
      "metadata": {
        "id": "ekaVdt0dWDwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0, shuffle = True)\n",
        "print(len(x_train))\n",
        "print(len(x_test))"
      ],
      "metadata": {
        "id": "wKPPPcXZyBOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_list3 = [ ]"
      ],
      "metadata": {
        "id": "YZ9YYyfnyDet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(model_name, est_c, est_pnlty):\n",
        "\n",
        "    mdl = ''\n",
        "\n",
        "    if model_name == 'Logistic Regression':\n",
        "        mdl = LogisticRegression()\n",
        "\n",
        "    elif model_name == 'Random Forest':\n",
        "        mdl = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
        "\n",
        "    elif model_name == 'Multinomial Naive Bayes':\n",
        "        mdl = MultinomialNB(alpha=1.0, fit_prior=True)\n",
        "\n",
        "    elif model_name == 'Support Vector Classifier':\n",
        "        mdl = SVC()\n",
        "\n",
        "    elif model_name == 'Decision Tree Classifier':\n",
        "        mdl = DecisionTreeClassifier()\n",
        "\n",
        "    elif model_name == 'K Nearest Neighbour':\n",
        "        mdl = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=4)\n",
        "\n",
        "    elif model_name == 'Gaussian Naive Bayes':\n",
        "        mdl = GaussianNB()\n",
        "\n",
        "    oneVsRest = OneVsRestClassifier(mdl)\n",
        "    oneVsRest.fit(X_train, y_train)\n",
        "    y_pred = oneVsRest.predict(X_test)\n",
        "\n",
        "    accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
        "\n",
        "    precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
        "\n",
        "    print(f'Test Accuracy Score of Basic {model_name}: % {accuracy}')\n",
        "    print(f'Precision : {precision}')\n",
        "    print(f'Recall : {recall}')\n",
        "    print(f'F1-score : {f1score}')\n",
        "\n",
        "    perform_list3.append(dict([\n",
        "        ('Model', model_name),\n",
        "        ('Test Accuracy', round(accuracy, 2)),\n",
        "        ('Precision', round(precision, 2)),\n",
        "        ('Recall', round(recall, 2)),\n",
        "        ('F1', round(f1score, 2))\n",
        "    ]))\n"
      ],
      "metadata": {
        "id": "1tni5rMGyFoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Logistic Regression', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "-zfo-aheyHnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Random Forest', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "F8mVnJYiyJdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Multinomial Naive Bayes', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "1QqH7Bx9yK8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_model('Support Vector Classifer', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "mvDrmA-2yMpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Decision Tree Classifier', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "2eF2ud6PyPPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_model('K Nearest Neighbour', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "JwgNYlFbyQ_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('Gaussian Naive Bayes', est_c=None, est_pnlty=None)"
      ],
      "metadata": {
        "id": "qzMopsNlySoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "model_performance = pd.DataFrame(data=perform_list3)\n",
        "model_performance = model_performance[['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1']]\n",
        "\n",
        "display(Markdown(\"# TF-IDF Model Performance metrics\"))\n",
        "\n",
        "display(model_performance)\n"
      ],
      "metadata": {
        "id": "mPwL7g9iyUMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_performance[\"Model\"]\n",
        "max_value = model_performance[\"Test Accuracy\"].max()\n",
        "print(\"The best accuracy of model is\", max_value,\"from Random\")"
      ],
      "metadata": {
        "id": "Wb0ZKMuqyWBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100 ,criterion='entropy' , random_state=0).fit(x_train, y_train)\n",
        "classifier\n",
        "y_pred = classifier.predict(x_test)\n"
      ],
      "metadata": {
        "id": "-AtbzODyyYOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = dataset['Description']\n",
        "y = dataset['CategoryId']\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "\n",
        "classifier = RandomForestClassifier(random_state=0)\n",
        "\n",
        "\n",
        "classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "\n",
        "new_text = [\"I am going to set up a new Microsoft business office in India. Stock market has good scope there!\"]\n",
        "new_text_tfidf = tfidf.transform(new_text)\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(new_text_tfidf)\n",
        "\n",
        "\n",
        "category_id_to_name = {\n",
        "    0: \"Business News\",\n",
        "    1: \"Tech News\",\n",
        "    2: \"Politics News\",\n",
        "    3: \"Sports News\",\n",
        "    4: \"Entertainment News\"\n",
        "}\n",
        "\n",
        "\n",
        "print(f\"The news is classified as: {category_id_to_name.get(y_pred[0], 'Unknown Category')}\")\n"
      ],
      "metadata": {
        "id": "c1ceIOAryZqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "id": "l8LXlTUN69RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support as score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "y9SUFrbk7B8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "X = dataset['Description'].astype(str).tolist()\n",
        "X_embeddings = bert_model.encode(X, show_progress_bar=True)\n",
        "\n",
        "y = np.array(dataset['CategoryId'])\n"
      ],
      "metadata": {
        "id": "hcBKF5-Z7E7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.3, random_state=42, shuffle=True)\n"
      ],
      "metadata": {
        "id": "iB-bhQdj7Gau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_performance = []\n",
        "\n",
        "def run_model_on_bert(model_name):\n",
        "    if model_name == 'Logistic Regression':\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "    elif model_name == 'Random Forest':\n",
        "        model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "    elif model_name == 'Multinomial Naive Bayes':\n",
        "        model = MultinomialNB()\n",
        "    elif model_name == 'Gaussian Naive Bayes':\n",
        "        model = GaussianNB()\n",
        "    elif model_name == 'Decision Tree':\n",
        "        model = DecisionTreeClassifier()\n",
        "    elif model_name == 'KNN':\n",
        "        model = KNeighborsClassifier(n_neighbors=10)\n",
        "    elif model_name == 'SVC':\n",
        "        model = SVC()\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    clf = OneVsRestClassifier(model)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
        "    precision, recall, f1score, support = score(y_test, y_pred, average='micro')\n",
        "\n",
        "    print(f\"{model_name} - Accuracy: {accuracy} | Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1score:.2f}\")\n",
        "\n",
        "    bert_performance.append({\n",
        "        'Model': model_name,\n",
        "        'Test Accuracy': accuracy,\n",
        "        'Precision': round(precision, 2),\n",
        "        'Recall': round(recall, 2),\n",
        "        'F1': round(f1score, 2)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "r5To6jhU7G7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in ['Logistic Regression', 'Random Forest', 'Multinomial Naive Bayes', 'Gaussian Naive Bayes', 'Decision Tree', 'KNN', 'SVC']:\n",
        "    run_model_on_bert(model)\n"
      ],
      "metadata": {
        "id": "c3wWNJ7n7Ikm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results_df = pd.DataFrame(bert_performance)\n",
        "bert_results_df = bert_results_df[['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1']]\n",
        "print(\"### BERT Model Performance Comparison ###\")\n",
        "print(bert_results_df)\n"
      ],
      "metadata": {
        "id": "ioxgSndP7K27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets\n"
      ],
      "metadata": {
        "id": "ZFx5As7FbhOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv(\"/content/train.csv\").dropna()\n",
        "df = df[['Description', 'Class Index']]\n",
        "df.columns = ['text', 'label']\n",
        "df['label'] = df['label'] - 1\n",
        "\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = Dataset.from_dict({'text': train_texts.tolist(), 'label': train_labels.tolist()})\n",
        "val_dataset = Dataset.from_dict({'text': val_texts.tolist(), 'label': val_labels.tolist()})\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy='epoch',\n",
        "    logging_dir='./logs',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1\n",
        ")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='micro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "kOX7o9dybkmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}